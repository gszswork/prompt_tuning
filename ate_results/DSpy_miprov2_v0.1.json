{
  "dspy_detailed_results_boolean_expressions_train10_val10": {
    "file": "dspy_detailed_results_boolean_expressions_train10_val10.csv",
    "num_rows": 420,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": -0.05114465395912034
      },
      "Engagement": {
        "ate": -0.16362111359790238
      },
      "Politeness": {
        "ate": -0.1284563972062823
      },
      "Intrinsic_load": {
        "ate": -0.017465310922692566
      },
      "Extraneous_load": {
        "ate": 0.12320193023195933
      },
      "Encourage_germane_load": {
        "ate": -0.16470954392469808
      },
      "Objectives": {
        "ate": -0.015394551527949336
      },
      "Metacognition": {
        "ate": -0.13764881308163882
      },
      "Demos": {
        "ate": -0.2482648211733459
      },
      "Structural_logic": {
        "ate": -0.10059538355840827
      },
      "Contextual_logic": {
        "ate": -0.08220368527049772
      },
      "Hallucination_awareness": {
        "ate": 0.0497411555430634
      }
    }
  },
  "dspy_detailed_results_GSM8K_train25_val25": {
    "file": "dspy_detailed_results_GSM8K_train25_val25.csv",
    "num_rows": 1744,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": 0.14290578197554682
      },
      "Engagement": {
        "ate": -0.10323394638272348
      },
      "Politeness": {
        "ate": 0.12868283364410735
      },
      "Intrinsic_load": {
        "ate": 0.1364892875339151
      },
      "Extraneous_load": {
        "ate": 0.12072843809308197
      },
      "Encourage_germane_load": {
        "ate": 0.13986580263659756
      },
      "Objectives": {
        "ate": -0.13082986636646138
      },
      "Metacognition": {
        "ate": 0.1386675636964927
      },
      "Demos": {
        "ate": 0.10712916420994788
      },
      "Structural_logic": {
        "ate": 0.03990034545335784
      },
      "Contextual_logic": {
        "ate": -0.13720271608673504
      },
      "Hallucination_awareness": {
        "ate": -0.12178668571856999
      }
    }
  },
  "dspy_detailed_results_StrategyQA_train10_val10": {
    "file": "dspy_detailed_results_StrategyQA_train10_val10.csv",
    "num_rows": 2460,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": -0.13894849242834778
      },
      "Engagement": {
        "ate": 0.1115893070074055
      },
      "Politeness": {
        "ate": -0.06687399548319287
      },
      "Intrinsic_load": {
        "ate": -0.01226500775781984
      },
      "Extraneous_load": {
        "ate": -0.0031007382239167172
      },
      "Encourage_germane_load": {
        "ate": 0.012026950100661439
      },
      "Objectives": {
        "ate": -0.10405485713354914
      },
      "Metacognition": {
        "ate": -0.05158002836390654
      },
      "Demos": {
        "ate": -0.03320328800743799
      },
      "Structural_logic": {
        "ate": -0.13894849242834778
      },
      "Contextual_logic": {
        "ate": 0.012315078277821943
      },
      "Hallucination_awareness": {
        "ate": -0.03848708616378527
      }
    }
  },
  "dspy_detailed_results_CommonsenseQA_train25_val25": {
    "file": "dspy_detailed_results_CommonsenseQA_train25_val25.csv",
    "num_rows": 1646,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": 0.0032578485098482507
      },
      "Engagement": {
        "ate": -0.0797898619902145
      },
      "Politeness": {
        "ate": -0.022106139752620893
      },
      "Intrinsic_load": {
        "ate": -0.07417590275046132
      },
      "Extraneous_load": {
        "ate": 0.010645807499197631
      },
      "Encourage_germane_load": {
        "ate": -0.0807612195609979
      },
      "Objectives": {
        "ate": -0.06574980655807262
      },
      "Metacognition": {
        "ate": -0.0807612195609979
      },
      "Demos": {
        "ate": -0.05794939784746054
      },
      "Structural_logic": {
        "ate": 0.010645807499197631
      },
      "Contextual_logic": {
        "ate": 0.010645807499197631
      },
      "Hallucination_awareness": {
        "ate": -0.03562569401447124
      }
    }
  },
  "dspy_detailed_results_coin_flip_train10_val10": {
    "file": "dspy_detailed_results_coin_flip_train10_val10.csv",
    "num_rows": 670,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": 0.9813209424208315
      },
      "Engagement": {
        "ate": 0.29548910254629385
      },
      "Politeness": {
        "ate": -0.020971686808522717
      },
      "Intrinsic_load": {
        "ate": 0.022138811707397454
      },
      "Extraneous_load": {
        "ate": -0.29548910254629385
      },
      "Encourage_germane_load": {
        "ate": 0.004992411173524306
      },
      "Objectives": {
        "ate": 0.019601710748208424
      },
      "Metacognition": {
        "ate": 0.00458870570973029
      },
      "Demos": {
        "ate": 0.01943582350508871
      },
      "Structural_logic": {
        "ate": 0.007036938256763452
      },
      "Contextual_logic": {
        "ate": 0.01222894518891067
      },
      "Hallucination_awareness": {
        "ate": 0.004588705698993151
      }
    }
  },
  "dspy_detailed_results_MultiArith_train25_val25": {
    "file": "dspy_detailed_results_MultiArith_train25_val25.csv",
    "num_rows": 1025,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": -0.04657608316686054
      },
      "Engagement": {
        "ate": 0.18071014476360434
      },
      "Politeness": {
        "ate": -0.04413708572351454
      },
      "Intrinsic_load": {
        "ate": 0.5086503523202578
      },
      "Extraneous_load": {
        "ate": -0.36478856258336445
      },
      "Encourage_germane_load": {
        "ate": 0.5697095379452697
      },
      "Objectives": {
        "ate": 0.320524219674138
      },
      "Metacognition": {
        "ate": -0.10736989080481496
      },
      "Demos": {
        "ate": 0.09624614547021344
      },
      "Structural_logic": {
        "ate": -0.005220819597105074
      },
      "Contextual_logic": {
        "ate": -0.11009610137433498
      },
      "Hallucination_awareness": {
        "ate": -0.05652753745214689
      }
    }
  },
  "dspy_detailed_results_date_understanding_train10_val10": {
    "file": "dspy_detailed_results_date_understanding_train10_val10.csv",
    "num_rows": 420,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": -0.9265171720328532
      },
      "Engagement": {
        "ate": 0.1379608734880793
      },
      "Politeness": {
        "ate": 0.04249968672785409
      },
      "Intrinsic_load": {
        "ate": 0.0169077543485495
      },
      "Extraneous_load": {
        "ate": 0.03329600986987972
      },
      "Encourage_germane_load": {
        "ate": -0.07052615587646885
      },
      "Objectives": {
        "ate": -0.05498587138415513
      },
      "Metacognition": {
        "ate": 0.07698011943576416
      },
      "Demos": {
        "ate": -0.04954703487729636
      },
      "Structural_logic": {
        "ate": -0.037340967882070954
      },
      "Contextual_logic": {
        "ate": 0.03935311097163111
      },
      "Hallucination_awareness": {
        "ate": 0.06203626363104037
      }
    }
  },
  "dspy_detailed_results_disambiguation_qa_train10_val10": {
    "file": "dspy_detailed_results_disambiguation_qa_train10_val10.csv",
    "num_rows": 420,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": -0.03355628296540509
      },
      "Engagement": {
        "ate": 0.18097288570391146
      },
      "Politeness": {
        "ate": 0.018233547461535604
      },
      "Intrinsic_load": {
        "ate": 0.02198472128410618
      },
      "Extraneous_load": {
        "ate": -0.0841440261543234
      },
      "Encourage_germane_load": {
        "ate": 0.12630885991644025
      },
      "Objectives": {
        "ate": 0.10318588303283911
      },
      "Metacognition": {
        "ate": 0.14595241477861484
      },
      "Demos": {
        "ate": 0.14267087311605756
      },
      "Structural_logic": {
        "ate": -0.05858624675043847
      },
      "Contextual_logic": {
        "ate": 0.02815447722472397
      },
      "Hallucination_awareness": {
        "ate": 0.07019129288296326
      }
    }
  },
  "dspy_detailed_results_last_letters_train10_val10": {
    "file": "dspy_detailed_results_last_letters_train10_val10.csv",
    "num_rows": 670,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": -0.06094047363562451
      },
      "Engagement": {
        "ate": 0.05511504601499047
      },
      "Politeness": {
        "ate": 0.0648615520007812
      },
      "Intrinsic_load": {
        "ate": 0.06530982863351778
      },
      "Extraneous_load": {
        "ate": -0.05511504601499047
      },
      "Encourage_germane_load": {
        "ate": 0.055049805276480505
      },
      "Objectives": {
        "ate": 0.04699000928985533
      },
      "Metacognition": {
        "ate": 0.05511504601499047
      },
      "Demos": {
        "ate": 0.06397116064023461
      },
      "Structural_logic": {
        "ate": 0.9379770552385904
      },
      "Contextual_logic": {
        "ate": -0.060510963039711894
      },
      "Hallucination_awareness": {
        "ate": 0.06381651416472574
      }
    }
  },
  "dspy_detailed_results_causal_judgement_train25_val25": {
    "file": "dspy_detailed_results_causal_judgement_train25_val25.csv",
    "num_rows": 612,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": -0.07045770075502279
      },
      "Engagement": {
        "ate": 0.0437898690172435
      },
      "Politeness": {
        "ate": -0.010015466381531455
      },
      "Intrinsic_load": {
        "ate": -0.11495418712880265
      },
      "Extraneous_load": {
        "ate": 0.05573685309357615
      },
      "Encourage_germane_load": {
        "ate": 0.061269523570562444
      },
      "Objectives": {
        "ate": -0.02124137120596783
      },
      "Metacognition": {
        "ate": -0.04665067746148092
      },
      "Demos": {
        "ate": 0.024285079826962132
      },
      "Structural_logic": {
        "ate": 0.0437898690172435
      },
      "Contextual_logic": {
        "ate": -0.0022102211946183024
      },
      "Hallucination_awareness": {
        "ate": 0.010150949720620845
      }
    }
  },
  "dspy_detailed_results_date_understanding_train25_val25": {
    "file": "dspy_detailed_results_date_understanding_train25_val25.csv",
    "num_rows": 675,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": -0.08079013029249234
      },
      "Engagement": {
        "ate": 0.09577554277333743
      },
      "Politeness": {
        "ate": 0.10878960726915492
      },
      "Intrinsic_load": {
        "ate": -0.09393008640418511
      },
      "Extraneous_load": {
        "ate": -0.0414155049823123
      },
      "Encourage_germane_load": {
        "ate": 0.07038344726006825
      },
      "Objectives": {
        "ate": -0.026233845178165537
      },
      "Metacognition": {
        "ate": 0.12734113526031138
      },
      "Demos": {
        "ate": 0.17479817637166972
      },
      "Structural_logic": {
        "ate": -0.04756846106405426
      },
      "Contextual_logic": {
        "ate": -0.11942453173759957
      },
      "Hallucination_awareness": {
        "ate": -0.07840927193513281
      }
    }
  },
  "dspy_detailed_results_last_letters_train25_val25": {
    "file": "dspy_detailed_results_last_letters_train25_val25.csv",
    "num_rows": 925,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": 0.05407351634837326
      },
      "Engagement": {
        "ate": 0.011147322405360484
      },
      "Politeness": {
        "ate": 0.22256752093439156
      },
      "Intrinsic_load": {
        "ate": -0.00125543882009736
      },
      "Extraneous_load": {
        "ate": 0.06520028902135463
      },
      "Encourage_germane_load": {
        "ate": -0.00657781685339271
      },
      "Objectives": {
        "ate": -0.2645556503124402
      },
      "Metacognition": {
        "ate": 0.00816694575382786
      },
      "Demos": {
        "ate": -0.20959885994068575
      },
      "Structural_logic": {
        "ate": 0.22327265033790766
      },
      "Contextual_logic": {
        "ate": 0.17823748879871884
      },
      "Hallucination_awareness": {
        "ate": -0.034068924997566044
      }
    }
  },
  "dspy_detailed_results_disambiguation_qa_train25_val25": {
    "file": "dspy_detailed_results_disambiguation_qa_train25_val25.csv",
    "num_rows": 675,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": -0.006018536618589284
      },
      "Engagement": {
        "ate": 0.02222207468088245
      },
      "Politeness": {
        "ate": 0.008888363176733362
      },
      "Intrinsic_load": {
        "ate": 0.04824398299874337
      },
      "Extraneous_load": {
        "ate": 0.04079813508159778
      },
      "Encourage_germane_load": {
        "ate": -0.050369189047026114
      },
      "Objectives": {
        "ate": -0.03649662352437583
      },
      "Metacognition": {
        "ate": -0.06788222178249376
      },
      "Demos": {
        "ate": -0.06720494645788397
      },
      "Structural_logic": {
        "ate": 0.02515064057327126
      },
      "Contextual_logic": {
        "ate": 0.011865922914176742
      },
      "Hallucination_awareness": {
        "ate": 0.009268424672008977
      }
    }
  },
  "dspy_detailed_results_causal_judgement_train10_val10": {
    "file": "dspy_detailed_results_causal_judgement_train10_val10.csv",
    "num_rows": 357,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": -0.024403783546509274
      },
      "Engagement": {
        "ate": 0.04978680236188923
      },
      "Politeness": {
        "ate": 0.015564512578754002
      },
      "Intrinsic_load": {
        "ate": 0.05926599091476068
      },
      "Extraneous_load": {
        "ate": -0.049538453195337666
      },
      "Encourage_germane_load": {
        "ate": 0.030337663730694197
      },
      "Objectives": {
        "ate": -0.06698698170497067
      },
      "Metacognition": {
        "ate": 0.06428961259422034
      },
      "Demos": {
        "ate": 0.017399079719275755
      },
      "Structural_logic": {
        "ate": -0.08134978268873976
      },
      "Contextual_logic": {
        "ate": 0.010441984276877788
      },
      "Hallucination_awareness": {
        "ate": 0.05877408893223275
      }
    }
  },
  "dspy_detailed_results_boolean_expressions_train25_val25": {
    "file": "dspy_detailed_results_boolean_expressions_train25_val25.csv",
    "num_rows": 675,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": -0.007642626149760574
      },
      "Engagement": {
        "ate": 0.022650254119909077
      },
      "Politeness": {
        "ate": 0.03315414852269442
      },
      "Intrinsic_load": {
        "ate": -0.021274118934196083
      },
      "Extraneous_load": {
        "ate": -0.0040790757101991345
      },
      "Encourage_germane_load": {
        "ate": -0.03394813530493433
      },
      "Objectives": {
        "ate": 0.9656759354445457
      },
      "Metacognition": {
        "ate": -0.02270960964157646
      },
      "Demos": {
        "ate": -0.054629642136047284
      },
      "Structural_logic": {
        "ate": -0.00412255158579593
      },
      "Contextual_logic": {
        "ate": -0.01798895328770979
      },
      "Hallucination_awareness": {
        "ate": -0.021445620547871316
      }
    }
  },
  "dspy_detailed_results_CommonsenseQA_train10_val10": {
    "file": "dspy_detailed_results_CommonsenseQA_train10_val10.csv",
    "num_rows": 1391,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": 0.06554087815252904
      },
      "Engagement": {
        "ate": -0.07132555015884227
      },
      "Politeness": {
        "ate": 0.052084608058341135
      },
      "Intrinsic_load": {
        "ate": -0.010950574321040756
      },
      "Extraneous_load": {
        "ate": 0.008773793007696587
      },
      "Encourage_germane_load": {
        "ate": -0.08211720764241531
      },
      "Objectives": {
        "ate": 0.0247789973530777
      },
      "Metacognition": {
        "ate": -0.05165557037671627
      },
      "Demos": {
        "ate": 0.04747447192421427
      },
      "Structural_logic": {
        "ate": 0.051001213270836676
      },
      "Contextual_logic": {
        "ate": 0.0697376309244414
      },
      "Hallucination_awareness": {
        "ate": -0.07132555015884227
      }
    }
  },
  "dspy_detailed_results_StrategyQA_train25_val25": {
    "file": "dspy_detailed_results_StrategyQA_train25_val25.csv",
    "num_rows": 2715,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": 0.10307585412497725
      },
      "Engagement": {
        "ate": -0.07843054021998808
      },
      "Politeness": {
        "ate": 0.0999561836915499
      },
      "Intrinsic_load": {
        "ate": 0.09919266588021433
      },
      "Extraneous_load": {
        "ate": -0.07734145762560803
      },
      "Encourage_germane_load": {
        "ate": 0.11196461868805886
      },
      "Objectives": {
        "ate": 0.09949812880968427
      },
      "Metacognition": {
        "ate": -0.10530122494275594
      },
      "Demos": {
        "ate": -0.08321113113947573
      },
      "Structural_logic": {
        "ate": 0.10132480214879723
      },
      "Contextual_logic": {
        "ate": 0.06307373106725514
      },
      "Hallucination_awareness": {
        "ate": -0.112251770696818
      }
    }
  },
  "dspy_detailed_results_GSM8K_train10_val10": {
    "file": "dspy_detailed_results_GSM8K_train10_val10.csv",
    "num_rows": 1489,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": 0.03125303997733893
      },
      "Engagement": {
        "ate": -0.0729252590901689
      },
      "Politeness": {
        "ate": -0.09798871260500018
      },
      "Intrinsic_load": {
        "ate": -0.10402820918050647
      },
      "Extraneous_load": {
        "ate": 0.017850034402929687
      },
      "Encourage_germane_load": {
        "ate": -0.04457662322643281
      },
      "Objectives": {
        "ate": -0.13763639944999506
      },
      "Metacognition": {
        "ate": -0.14174291170793554
      },
      "Demos": {
        "ate": -0.027104428568398294
      },
      "Structural_logic": {
        "ate": 0.08245010694612735
      },
      "Contextual_logic": {
        "ate": -0.09520357198433302
      },
      "Hallucination_awareness": {
        "ate": -0.10790936376642571
      }
    }
  },
  "dspy_detailed_results_coin_flip_train25_val25": {
    "file": "dspy_detailed_results_coin_flip_train25_val25.csv",
    "num_rows": 925,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": -0.010276494239660037
      },
      "Engagement": {
        "ate": 0.0176086687883174
      },
      "Politeness": {
        "ate": 0.9741863936820399
      },
      "Intrinsic_load": {
        "ate": 0.015578272459041384
      },
      "Extraneous_load": {
        "ate": -0.010521042007482532
      },
      "Encourage_germane_load": {
        "ate": 0.0176754976491725
      },
      "Objectives": {
        "ate": -0.010265248809936707
      },
      "Metacognition": {
        "ate": 0.01557311917796337
      },
      "Demos": {
        "ate": 0.015336267605471448
      },
      "Structural_logic": {
        "ate": -0.010521042007482532
      },
      "Contextual_logic": {
        "ate": -0.03690234930395388
      },
      "Hallucination_awareness": {
        "ate": 0.017803021141947244
      }
    }
  },
  "dspy_detailed_results_MultiArith_train10_val10": {
    "file": "dspy_detailed_results_MultiArith_train10_val10.csv",
    "num_rows": 770,
    "num_features": 12,
    "ate_results": {
      "Clarity": {
        "ate": -0.45741693183448795
      },
      "Engagement": {
        "ate": 0.10357639392419528
      },
      "Politeness": {
        "ate": -0.36644695342533024
      },
      "Intrinsic_load": {
        "ate": -0.09490225933727917
      },
      "Extraneous_load": {
        "ate": -0.30847509084281965
      },
      "Encourage_germane_load": {
        "ate": 0.10387906122065857
      },
      "Objectives": {
        "ate": -0.2609873695865377
      },
      "Metacognition": {
        "ate": 0.1030571338601961
      },
      "Demos": {
        "ate": -0.2143569181997324
      },
      "Structural_logic": {
        "ate": -0.3124300585621502
      },
      "Contextual_logic": {
        "ate": -0.0851262691930764
      },
      "Hallucination_awareness": {
        "ate": -0.255904618819801
      }
    }
  }
}