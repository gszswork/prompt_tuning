{
  "prompt": "1. **Clarity**: The degree to which prompts are clear and direct (across turns) while minimizing unnecessary ambiguity, complexity, and confusion. \n\n2. **Engagement**: The extent to which the prompts explicitly encourage the models to gather the necessary details and requirements by asking questions of clarification or confirmation. \n\n3. **Politeness**: The degree to which prompts maintain respectful, professional, and contextspecific politeness, including the use of courteous language (e.g., \"please\", \"thank you\"). \n\n4. **Intrinsic_load**: The degree of prompts in explicitly guiding models to break complex tasks into actionable steps aligned with LM skills. \n\n5. **Extraneous_load**: The extent to which prompts minimize unnecessary complexity via simplifying language and removing redundant or irrelevant information to reduce unnecessary load. \n\n6. **Encourage_germane_load**: The degree to which prompts explicitly engage models with their prior knowledge or deep working memory (e.g., \"ask itself\") to integrate it with existing and new knowledge for problem-solving. \n\n7. **Objectives**: How well prompts explicitly communicate the task objectives, including expected personae, outputs, formats, constraints, audiences, and other applicable criteria. \n\n8. **Metacognition**: This assesses prompts in explicitly guiding models to reason, selfmonitor, and self-verify outputs to meet expectations and enhance reliability. \n\n9. **Demos**: The extent to which the prompts explicitly include examples, demonstrations, and counterexamples to illustrate the desired output. Score the prompts from 0~10 based on the demo qualities. \n\n10. **Structural_logic**: This evaluates the logical clarity and coherence of prompts' structure, and the progression between components. \n\n11. **Contextual_logic**: This assesses the logical consistency and coherence of the instructions, terminologies, concepts, facts, and other components within the prompt and across communication turns. \n\n12. **Hallucination_awareness**: The extent to which prompts explicitly guide models to generate factual and evidence-based responses while minimizing speculative or unsupported claims. "
}
